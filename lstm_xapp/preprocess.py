from __future__ import annotations

import math
from dataclasses import dataclass
from typing import Dict, List, Sequence, Tuple

import numpy as np
import pandas as pd

from .config import FeatureSpec, TrainingConfig


@dataclass
class StandardScaler:
    """Minimal sklearn-like scaler (mean/std) without extra dependencies."""

    mean_: np.ndarray
    std_: np.ndarray

    @staticmethod
    def fit(x: np.ndarray, eps: float = 1e-8) -> "StandardScaler":
        mean = x.mean(axis=0)
        std = x.std(axis=0)
        std = np.where(std < eps, 1.0, std)
        return StandardScaler(mean_=mean, std_=std)

    def transform(self, x: np.ndarray) -> np.ndarray:
        return (x - self.mean_) / self.std_

    def inverse_transform(self, x: np.ndarray) -> np.ndarray:
        return x * self.std_ + self.mean_


def _minute_of_day(minute: int) -> int:
    return int(minute % 1440)


def _time_sincos(minute: int) -> Tuple[float, float]:
    m = _minute_of_day(minute)
    angle = 2.0 * math.pi * (m / 1440.0)
    return math.sin(angle), math.cos(angle)


def _is_business_hour(minute: int) -> int:
    hour = (minute // 60) % 24
    return int(9 <= hour <= 17)


def _is_event(minute: int) -> int:
    # Mirrors simulator.net_sim.Urban5GSimulator.is_event_time
    day = minute // 1440
    local_min = minute % 1440
    event_start = 1080 + (day % 3) * 10
    return int(event_start <= local_min <= event_start + 180)


def build_feature_frame(df: pd.DataFrame, feature_spec: FeatureSpec) -> pd.DataFrame:
    """Builds a feature DataFrame aligned with the simulator outputs.

    Expected columns if generated by ``Urban5GSimulator.to_dataframe()``:
    - minute (absolute minute index)
    - traffic
    - interference_dbm
    - tx_power_dbm
    - sinr_db
    """

    if "minute" not in df.columns:
        raise ValueError("DataFrame must contain a 'minute' column.")

    feat_cols: Dict[str, np.ndarray] = {}

    if feature_spec.use_traffic:
        feat_cols["traffic"] = df["traffic"].to_numpy(dtype=np.float32)
    if feature_spec.use_interference:
        key = "interference_dbm" if "interference_dbm" in df.columns else "interference"
        feat_cols["interference_dbm"] = df[key].to_numpy(dtype=np.float32)
    if feature_spec.use_sinr:
        feat_cols["sinr_db"] = df["sinr_db"].to_numpy(dtype=np.float32)
    if feature_spec.use_tx_power:
        key = "tx_power_dbm" if "tx_power_dbm" in df.columns else "tx_power"
        feat_cols["tx_power_dbm"] = df[key].to_numpy(dtype=np.float32)

    minute_arr = df["minute"].to_numpy(dtype=np.int64)
    if feature_spec.use_time_sincos:
        s = np.empty(len(df), dtype=np.float32)
        c = np.empty(len(df), dtype=np.float32)
        for i, m in enumerate(minute_arr):
            si, co = _time_sincos(int(m))
            s[i] = si
            c[i] = co
        feat_cols["tod_sin"] = s
        feat_cols["tod_cos"] = c

    if feature_spec.use_is_event:
        feat_cols["is_event"] = np.array([_is_event(int(m)) for m in minute_arr], dtype=np.float32)
    if feature_spec.use_is_business_hour:
        feat_cols["is_business_hour"] = np.array([_is_business_hour(int(m)) for m in minute_arr], dtype=np.float32)

    return pd.DataFrame(feat_cols)


def build_targets(df: pd.DataFrame) -> pd.DataFrame:
    """Targets to predict.

    The paper highlights traffic forecasting and SINR trend anticipation.
    Here we predict both traffic and SINR.
    """

    for col in ("traffic", "sinr_db"):
        if col not in df.columns:
            raise ValueError(f"DataFrame missing target column: {col}")
    return df[["traffic", "sinr_db"]].astype(np.float32)


def make_supervised_sequences(
    features: np.ndarray,
    targets: np.ndarray,
    cfg: TrainingConfig,
) -> Tuple[np.ndarray, np.ndarray]:
    """Converts (T, F) and (T, Y) arrays into supervised sequences.

    Returns:
      X: (N, lookback, F)
      y: (N, horizon, Y)
    """

    T = features.shape[0]
    lookback = cfg.lookback
    horizon = cfg.horizon
    if T < lookback + horizon:
        raise ValueError("Not enough timesteps to build sequences.")

    xs: List[np.ndarray] = []
    ys: List[np.ndarray] = []
    for t in range(lookback, T - horizon):
        xs.append(features[t - lookback : t])
        ys.append(targets[t : t + horizon])
    X = np.stack(xs, axis=0).astype(np.float32)
    y = np.stack(ys, axis=0).astype(np.float32)
    return X, y


def train_val_split(
    X: np.ndarray,
    y: np.ndarray,
    val_ratio: float = 0.15,
) -> Tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray]:
    n = X.shape[0]
    n_val = max(1, int(n * val_ratio))
    n_train = n - n_val
    return X[:n_train], y[:n_train], X[n_train:], y[n_train:]
